{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Capstone Project by Niklas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem description & Background\n",
    "\n",
    "Vehicle accidents can have tremendous impacts on a person's life - both from a health perspective but also on a financial one.\n",
    "On those, multiple factors like traffic, rain, snow, wind,\n",
    "or road conditions can determine the likeliness and severity of an accident.\n",
    "\n",
    "*Can it be possible to determine and quantify the risk even before starting the engine by knowing certain conditions that can be expected during the ride?*\n",
    "\n",
    "So, the goal of this research is to help people to evaluate the overall risk of a vehicle trip out of the combination of likeliness\n",
    "of an accident and potential impact/severity, so that drivers can make better decisions for themselves and other people."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data description and usage to solve the problem\n",
    "\n",
    "For this Capstone Project, a Collision data set will be used that includes information about almost 200,000 accidents recorded in Seattle, WA, since the year 2004.\n",
    "From those accidents, 5085 did not involve vehicles but just pedestrians and cyclists. Those will be excluded from the analysis.\n",
    "Overall, the data set contains various variables with possible influence on the target variable, the **SEVERITY** of an accident.\n",
    "These predictor variables include the following:\n",
    "\n",
    "- *WEATHER:* Describing weather conditions with attribute options like Clear, Overcast, Raining, Fog, Crosswind, Snow, and other\n",
    "- *ROADCOND:* Describing road conditions with attribute options like Dry, Wet, Ice, Oil, Standing Water, and other\n",
    "- *LIGHTCOND:* Describing light conditions with attribute options like Daylight, Dawn, and Dark with different status of artificial/street light\n",
    "- *ADDRTYPE:* Describing the address type where a collision took place with the options Alley, Block, and Intersection\n",
    "\n",
    "Going forward, this data will be examined via exploratory analysis to identify the most influential predictor variables.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methodology section\n",
    "\n",
    "## 1 Exploratory Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the pandas library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the data set containing car collisions from Seattle, Washington."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"Data-Collisions.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the data & copy to new dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "SEVERITYCODE     int64\nADDRTYPE        object\nWEATHER         object\nROADCOND        object\nLIGHTCOND       object\ndtype: object"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = df_raw[['SEVERITYCODE','ADDRTYPE','WEATHER','ROADCOND','LIGHTCOND']]\n",
    "df_cleaned = df_columns.copy()\n",
    "df_cleaned.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Delete the rows with missing, \"Unknown\" or \"Other\" data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "df_cleaned.dropna(inplace=True)\n",
    "\n",
    "df_cleaned[\"ADDRTYPE\"] = df_cleaned[\"ADDRTYPE\"].astype('category')\n",
    "df_cleaned[\"WEATHER\"] = df_cleaned[\"WEATHER\"].astype('category')\n",
    "df_cleaned[\"ROADCOND\"] = df_cleaned[\"ROADCOND\"].astype('category')\n",
    "df_cleaned[\"LIGHTCOND\"] = df_cleaned[\"LIGHTCOND\"].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Analysis of potential dangerous spots for accidents\n",
    "\n",
    "Count the values of where the car collisions took place."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "Block           123321\nIntersection     63462\nAlley              742\nName: ADDRTYPE, dtype: int64"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[\"ADDRTYPE\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data illustrates that almost 70% of all recorded collisions where recorded in blocks, whereas intersections make up about 30%. Alley collisions are quite rare with under 1% of the total count."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Count the values of what the weather conditions where when the car collisions took place."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "Clear                       110499\nRaining                      32976\nOvercast                     27551\nUnknown                      14059\nSnowing                        896\nOther                          790\nFog/Smog/Smoke                 563\nSleet/Hail/Freezing Rain       112\nBlowing Sand/Dirt               49\nSevere Crosswind                25\nPartly Cloudy                    5\nName: WEATHER, dtype: int64"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[\"WEATHER\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mostly, the weather was clear during collisions followed by rain, overcast, and unknown conditions. Snowing, other, and Fog/Smog/Smoke make up another small percentage. Conditions such as Sleet/Hail/Freezing Rain or Blowing Sand/Dirt make up some outliers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Count the values of what the road conditions where when the car collisions took place."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "Dry               123736\nWet                47223\nUnknown            14009\nIce                 1193\nSnow/Slush           992\nOther                124\nStanding Water       111\nSand/Mud/Dirt         73\nOil                   64\nName: ROADCOND, dtype: int64"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[\"ROADCOND\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The road conditions that where recorded show values that on first hand match with the weather recorded. Streets were dry in most cases, followed by wet conditions, unknown conditions and Ice, Snow and Slush."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last variable represents the light conditions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned[\"LIGHTCOND\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most collisions (over 50%) where recorded during daylight. This is followed by various darker light conditions such as dark (street lights on), dusk, dawn, and dark without street lights."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Transferring labels to numbers\n",
    "\n",
    "To prepare the data for the Machine Learning algorithm processing, the object values are transformed into numerical ones."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned[\"ADDRTYPE_INT\"] = df_cleaned[\"ADDRTYPE\"].cat.codes\n",
    "df_cleaned[\"WEATHER_INT\"] = df_cleaned[\"WEATHER\"].cat.codes\n",
    "df_cleaned[\"ROADCOND_INT\"] = df_cleaned[\"ROADCOND\"].cat.codes\n",
    "df_cleaned[\"LIGHTCOND_INT\"] = df_cleaned[\"LIGHTCOND\"].cat.codes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the first 10 lines of the whole dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Ratio Property damage vs. Injury of variable conditions\n",
    "\n",
    "In order to get a better understanding of conditions leading to either only property damage or even injuries, the variables will be investigated.\n",
    "As a result, in a table, the percentage of property damage vs. injury is labeled for each individual value of all given attributes.\n",
    "\n",
    "In the first table, the addresstype is investigated."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "addr_prob = pd.crosstab(index=df_cleaned[\"SEVERITYCODE\"],\n",
    "                           columns=df_cleaned[\"ADDRTYPE\"], margins=True)\n",
    "\n",
    "addr_prob.index = [\"Property Damage\", \"Injury\", \"Total Column\"]\n",
    "\n",
    "addr_prob/addr_prob.loc[\"Total Column\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When analyzing the addresstype, the following observations can be made under consideration of the overall ratio between property damages and injuries (about 70/30):\n",
    "\n",
    "- Alleys show a strong tendency for property damage collisions and only a small amount of injury collisions\n",
    "- Blocks show a medium tendency for property damage collisions and only a small amount of injury collisions\n",
    "- Intersections show a mild tendency for injury collisions over property damage collisions compared to the overall numbers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_prob = pd.crosstab(index=df_cleaned[\"SEVERITYCODE\"],\n",
    "                           columns=df_cleaned[\"WEATHER\"], margins=True)\n",
    "\n",
    "weather_prob.index = [\"Property Damage\", \"Injury\", \"Total Column\"]\n",
    "\n",
    "weather_prob/weather_prob.loc[\"Total Column\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When analyzing the weather, the following observations can be made under consideration of the overall ratio between property damages and injuries (about 70/30):\n",
    "\n",
    "- clear weather, fog/smog/smoke, and rain seem to increase the chance of injury collisions\n",
    "- blowing sand/dirt, severe crosswinds, and especially sleet/hail/freezing rain, and snowing seem to increase the chance of property damages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "road_prob = pd.crosstab(index=df_cleaned[\"SEVERITYCODE\"],\n",
    "                           columns=df_cleaned[\"ROADCOND\"], margins=True)\n",
    "\n",
    "road_prob.index = [\"Property Damage\", \"Injury\", \"Total Column\"]\n",
    "\n",
    "road_prob/road_prob.loc[\"Total Column\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When analyzing the road conditions, the following observations can be made under consideration of the overall ratio between property damages and injuries (about 70/30):\n",
    "\n",
    "- dry roads, wet roads, and especially oiled roads increase the chance of injury collisions\n",
    "- iced roads, standing water, and especially snow/slush increase the likelihood of property damage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "light_prob = pd.crosstab(index=df_cleaned[\"SEVERITYCODE\"],\n",
    "                           columns=df_cleaned[\"LIGHTCOND\"], margins=True)\n",
    "\n",
    "light_prob.index = [\"Property Damage\", \"Injury\", \"Total Column\"]\n",
    "\n",
    "light_prob/light_prob.loc[\"Total Column\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When analyzing the light conditions, the following observations can be made under consideration of the overall ratio between property damages and injuries (about 70/30):\n",
    "\n",
    "- dark conditions without artificial street lighting seem to increase the chance of property damage\n",
    "- the other conditions do not show specific tendencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Machine Learning Algorithms\n",
    "\n",
    "During the Support Vector Machines analysis I detected the algorithm to classify the whole dataset to the value 1 - property damage.\n",
    "As a reason, the strong ratio from 70/30 (property/injury) in the data set is considered.\n",
    "Therefore, the set will be resampled first, to then go another iteration with all algorithms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the resample library from sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resampling the dataset and display the number of 1 and 2 value rows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned_majority = df_cleaned[df_cleaned.SEVERITYCODE==1]\n",
    "df_cleaned_minority = df_cleaned[df_cleaned.SEVERITYCODE==2]\n",
    "\n",
    "#Downsample majority class\n",
    "df_cleaned_majority_new = resample(df_cleaned_majority,\n",
    "                                        replace=False,\n",
    "                                        n_samples=56883,\n",
    "                                        random_state=247)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_cleaned_bal = pd.concat([df_cleaned_majority_new, df_cleaned_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_cleaned_bal.SEVERITYCODE.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Separating the dataset into the target variable and the predictor variables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#split data\n",
    "\n",
    "y_data = np.asarray(df_cleaned_bal['SEVERITYCODE'])\n",
    "y_data[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_data = df_cleaned_bal.drop(['SEVERITYCODE','ADDRTYPE','WEATHER','ROADCOND','LIGHTCOND'], axis=1)\n",
    "x_data = np.asarray(x_data)\n",
    "x_data [0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalizing the x_data, so that all variables can be compared."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x_data = preprocessing.StandardScaler().fit(x_data).transform(x_data)\n",
    "x_data[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting the data into test and train sets. Testsize is set with 25% of the total dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "print(\"number of test samples :\", x_test.shape[0])\n",
    "print(\"number of training samples:\",x_train.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.1 K - Nearest Neighbours\n",
    "\n",
    "The first method that is applied is KNN. Iteratively, K=13 was determined to have the highest accuracy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 13\n",
    "\n",
    "#Train Model and Predict\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(x_train,y_train)\n",
    "neigh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat_knn = neigh.predict(x_test)\n",
    "\n",
    "yhat_knn[0:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determining the ideal K value for KNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "Ks = 15\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "for n in range(1,Ks):\n",
    "\n",
    "    #Train Model and Predict\n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(x_train,y_train)\n",
    "    yhat_knn=neigh.predict(x_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat_knn)\n",
    "\n",
    "\n",
    "    std_acc[n-1]=np.std(yhat_knn==y_test)/np.sqrt(yhat_knn.shape[0])\n",
    "\n",
    "mean_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot a graph to illustrate the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,Ks),mean_acc,'g')\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3 x std'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Neighbours (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.2 Decision tree\n",
    "\n",
    "The second method that is applied is the Decision Tree."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The max_depth is set with 7 - describing the longest path from the tree's roof to a leaf."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 7)\n",
    "df_cleaned_tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned_tree.fit(x_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cleaned_predTree = df_cleaned_tree.predict(x_test)\n",
    "\n",
    "print (df_cleaned_predTree [0:5])\n",
    "print (y_test [0:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.3 SVM with poly kernel\n",
    "\n",
    "The third ML algorithm applied is the SVM with a poly kernel, during test iterations set with a C value of 0.05."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='poly', C=0.25)\n",
    "clf.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat_svm = clf.predict(x_test)\n",
    "yhat_svm [0:25]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.4 Logistic Regression\n",
    "\n",
    "The last ML technique applied to the dataset is the logistic regression model with a C value of 0.5."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C=0.025, solver='liblinear').fit(x_train,y_train)\n",
    "LR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat_LR = LR.predict(x_test)\n",
    "yhat_LR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yhat_prob = LR.predict_proba(x_test)\n",
    "yhat_prob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.5 Model Evaluation\n",
    "\n",
    "In the final step, the four ML algorithms are ranked based on two key metrics - the jaccard similarity score and the f1 score. Additionally, for the logistic regression, the log loss is also calculated."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate the metrics for all four methods."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jc_1=jaccard_similarity_score(y_test, yhat_knn)\n",
    "fs_1=f1_score(y_test, yhat_knn, average='weighted')\n",
    "\n",
    "jc_2=jaccard_similarity_score(y_test, df_cleaned_predTree)\n",
    "fs_2=f1_score(y_test, df_cleaned_predTree, average='weighted')\n",
    "\n",
    "jc_3=jaccard_similarity_score(y_test, yhat_svm)\n",
    "fs_3=f1_score(y_test, yhat_svm, average='weighted')\n",
    "\n",
    "jc4=jaccard_similarity_score(y_test, yhat_LR)\n",
    "fs4=f1_score(y_test, yhat_LR, average='weighted')\n",
    "ll4=log_loss(y_test, yhat_prob)\n",
    "\n",
    "list_jc = [jc_1, jc_2, jc_3, jc4]\n",
    "list_fs = [fs_1, fs_2, fs_3, fs4]\n",
    "list_ll = ['N/A', 'N/A', 'N/A', ll4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create and display a final table, comparing the accuracy metrics for the four applied algorithms."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# formulate the report format\n",
    "df = pd.DataFrame(list_jc, index=['KNN','Decision Tree','SVM','Logistic Regression'])\n",
    "df.columns = ['Jaccard']\n",
    "df.insert(loc=1, column='F1-score', value=list_fs)\n",
    "df.insert(loc=2, column='LogLoss', value=list_ll)\n",
    "df.columns.name = 'Algorithm'\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When analyzing the table, the following observations can be made:\n",
    "\n",
    "- KNN is the least accurate method\n",
    "- The Decision Tree has the best accuracy in terms of jaccard score and f1\n",
    "- SVM has a high accuracy but it remains questionable if the trade-off between the needed computing power and the results makes it a worthy solution\n",
    "- The Linear Regression has almost the same accuracy as the Decision Tree in terms of the metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results\n",
    "\n",
    "Decision Tree and Linear Regression are recommended as the most fitting methods for predicting the severity of a collision.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discussion\n",
    "This report has to be viewed under consideration of several potential weaknesses whose influence could be investigated going further:\n",
    "\n",
    "- \"Other\" and \"Unknown\" values can be filtered out of the dataset for the variables \"WEATHER\", \"ROADCOND\", and \"LIGHTCOND\"\n",
    "- Other variables could have a strong influence, such as alcohol and tiredness level of the driver\n",
    "- Only two different severity types were investigated, potentially there are more\n",
    "- From those investigated, the injuries can also have involved pedestrians or cyclists who where not considered in this research\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Overall, certain conditions increase the likelihood of car collisions that involve people getting injured:\n",
    "\n",
    "As we have seen, at intersections that danger of a collision resulting in injuries is the highest in the dataset.\n",
    "Also, clear weather, fog/smog/smoke, and rain seem to increase injuries as well as dry, wet, and especially oiled roads.\n",
    "\n",
    "Other places - alleys and blocks - have a lower risk of injuries and are more related to property damage.\n",
    "Also, blowing sand/dirt, severe crosswinds, and especially sleet/hail/freezing rain, and snowing seem to increase the chance of property damages.\n",
    "They are accompagnied by iced roads, standing water, and especially snow/slush who also increase the likelihood of property damage.\n",
    "\n",
    "When trying to forecast the severity of a potential car collision, four Machine Learning algorithms were trained and tested."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python2",
   "language": "python",
   "display_name": "Python 2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}